{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-43e1b6ef-3eb8-4f7f-8556-63370a9241c2",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "6580c1bc",
        "execution_millis": 0,
        "execution_start": 1619059519083,
        "deepnote_cell_type": "code"
      },
      "source": "#common distributions\n#**normal - good for everything in general\n#**poisson - good for number of occurences \n#exponential  \n#beta \n#gamma\n#**uniform \n#**binomial - need this for indicators too ",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Working with Floats",
      "metadata": {
        "tags": [],
        "cell_id": "00002-2fb27c81-3348-45b6-995d-049eb1d3feb4",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-cc9254f3-23f7-42b9-8155-1cb7252f65c5",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "f19cbaea",
        "execution_millis": 1,
        "execution_start": 1619059519750,
        "deepnote_cell_type": "code"
      },
      "source": "def check_parameters(parameters):\n    for p in parameters:\n        if type(p) not in [int, float]:\n            raise SyntaxError(\"parameters must to integers or floats\")\ncheck_parameters([20, 2.5])",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-4de94fb6-625e-463d-9888-f0b345df026d",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "1024f1d",
        "execution_millis": 61,
        "execution_start": 1619059519962,
        "deepnote_cell_type": "code"
      },
      "source": "import re #Regex library\nimport yaml\nimport pandas as pd \nfrom yaml import load, dump\ntry:\n    from yaml import CLoader as Loader, CDumper as Dumper\nexcept ImportError:\n    from yaml import Loader, Dumper\nimport numpy as np # name, patientid, date of death, lat, lon\n#Float Generator\n\n#-column: blood sugar\n#   type: float\n#   distribution: {name: 'normal', mean: '5.5', std: '1.5'}\n#   constraints: {upper:8 , lower:2}\n\n\n# name - string field name\n# distribution - dictionary \n# constraints - dictionary\n# size - num rows\n\n\ndef float_generator(distribution, constraints, size):\n    # Extract parameters from distribution\n    # Use the correct function from np and pass in proper parameters + size\n    # Clip the distribution based off of lower and upper constraints\n    # Insert the values into a Series\n   \n   #checks if the 'size' input is an integer\n    if type(size) != int:\n        raise SyntaxError(\"size must be an integer\")\n    \n    name = distribution['name']\n    \n    #generates data with numpy random distributions \n    if name == 'normal':\n        mean, std = distribution['mean'], distribution['std']\n        check_parameters([mean, std])\n        data = np.random.normal(mean, std, size)\n    \n\n    elif name == 'lognormal':\n        mean, std = distribution['mean'], distribution['std']\n        check_parameters([mean, std])\n        data = np.random.lognormal(mean, std, size)\n    \n    elif name == 'uniform':\n        a, b = distribution['a'], distribution['b']\n        check_parameters([a, b])\n        if a > b:\n            raise SyntaxError(\"a must be less than b\")\n        data = np.random.uniform(a, b, size)\n\n    elif name == 'binomial':\n        n, p = distribution['n'], distribution['prob']\n        check_parameters([n, p])\n        data = np.random.binomial(n, p, size)\n    \n    elif name == 'poisson':\n        lam = distribution['lam']\n        check_parameters([lam])\n        data = np.random.poisson(lam, size)\n    \n    elif name == 'beta':\n        alpha, beta = distribution['alpha'], distribution['beta']\n        check_parameters([alpha, beta])\n        data = np.random.beta(alpha, beta, size)\n    \n    elif name == 'gamma':\n        shape, scale = distribution['shape'], distribution['scale']\n        check_parameters([shape, scale])\n        data = np.random.gamma(shape, scale, size)\n    \n    elif name == 'exponential':\n        lam = distribution['lam']\n        check_parameters([lam])\n        data = np.random.exponential(lam, size)\n\n    #checks if 'name' input is supported by generator \n    else:\n        raise SyntaxError(name +\" not recognized\")\n\n    #checks for constraints \n    if constraints == None:\n        return data.tolist()\n\n    #clip outliers based on constraint conditions\n    elif 'max' not in constraints:\n        data = np.clip(data, a_min = constraints['min'], a_max = None)\n        return data.tolist()\n    elif 'min' not in constraints:\n        data = np.clip(data, a_min = None, a_max = constraints['max'])\n        return data.tolist()\n    elif 'min' in constraints and 'max' in constraints: \n        data = np.clip(data, a_min = constraints['min'], a_max = constraints['max'])\n        return data.tolist()\n    #raises error if 'constraints' inputs are invalid\n    else:\n        raise SyntaxError(\"min and max not recognized\")\n\nfloat_generator({'name':'normal', 'mean': 20,'std': 2}, {'max': None, 'min':2}, 20)\n\n\n\n\n        \n\n    \n    ",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "[21.143467915067635,\n 19.19672846130804,\n 19.758622798722833,\n 20.12147825431966,\n 22.200841549825604,\n 19.1663508050057,\n 15.347278158865784,\n 16.801651275190846,\n 18.521988781881742,\n 18.060327604027258,\n 20.75069134771129,\n 20.391292558032905,\n 20.000336076491482,\n 23.189666096997183,\n 18.11145591809387,\n 20.635059548748547,\n 21.27396849960768,\n 21.4120638102704,\n 17.448926048910618,\n 20.53519168650539]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Int Generator ",
      "metadata": {
        "tags": [],
        "cell_id": "00003-5c482760-90d2-46c9-88ba-4887d1184c6d",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00003-f718e678-c0ee-4a57-8233-6507d1201107",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b15a6b8e",
        "execution_millis": 10,
        "execution_start": 1619059520616,
        "deepnote_cell_type": "code"
      },
      "source": "def int_generator(distribution, constraints, size):\n    # Extract parameters from distribution\n    # Use the correct function from np and pass in proper parameters + size\n    # Clip the distribution based off of lower and upper constraints\n    # Convert values to int type \n    # Insert the values into a Series\n\n    #generate data with np random distributions \n    #checks if user inputs a bernoulli distribution and uses a binomial to generate it\n    if type(size) != int:\n        raise SyntaxError(\"size must be an integer\")\n    \n    if distribution['name'] == 'bernoulli':\n        data = np.random.binomial(1, distribution['p'], size)\n        data = data.tolist()\n    \n    else:\n        data = float_generator(distribution, constraints, size)\n    \n    #rounds values and convert to ints\n    return np.round(data).astype(int).tolist() \n\nint_generator({'name':'normal', 'mean': 20.5,'std': 2.5}, {'max':30, 'min':2}, 10)\n#int_generator({'name':'bernoulli', 'p': 0.5}, {'upper':'na', 'lower':'na'}, 10)",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "[25, 18, 20, 20, 22, 19, 22, 16, 23, 16]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-44770457-6564-417d-9679-dc761662053f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "33640db0",
        "execution_millis": 4,
        "execution_start": 1619059521145,
        "deepnote_cell_type": "code"
      },
      "source": "def string_bestower(dist, choices, i, data_list, number_of_points):\n    for j in range(number_of_points):\n        if dist['name'] == 'normal':\n            assert 'mean' in dist and 'std' in dist, \"must provide mean and std for normal dist\"\n            a = int(np.random.normal(loc=dist['mean'], scale=dist['std']))\n        \n        elif dist['name'] == 'lognormal':\n            assert 'mean' in dist and 'std' in dist, \"must provide mean and std for lognormal dist\"\n            a = int(np.random.lognormal(loc=dist['mean'], scale=dist['std']))\n\n        elif dist['name'] in ['binomial', 'bernoulli']:\n            assert 'n' in dist and 'prob' in dist, \"must provide n and prob for binomial or bernoulli\"\n            a = int(np.random.binomial(n=dist['n'], p=dist['prob']))\n        \n        elif dist['name'] == 'poisson':\n            assert 'lam' in dist, \"must provide lam for poission\"\n            a = int(np.random.poisson(dist['lam']))\n        \n        elif dist['name'] == 'beta':\n            assert 'alpha' in dist and 'beta' in dist, \"must provide alpha and beta for beta dist\"\n            a = int(np.random.beta(dist['alpha'], dist['beta']))\n        \n        elif dist['name'] == 'gamma':\n            assert 'shape' in dist and 'scale' in dist, 'must provide shape and scale for gamma dist'\n            a = int(np.random.gamma(dist['shape'], dist['scale']))\n        \n        elif dist['name'] == 'exponential':\n            assert 'lam' in dist, 'must provide lam for exponential'\n            a = int(np.random.exponential(dist['lam']))\n        \n        elif dist['name'] == 'uniform':\n            assert 'min' in dist and 'max' in dist, 'must provide min and max for uniform dist (separate from constraints)'\n            a = int(np.random.randint(dist['min'], dist['max']))\n        \n        else:\n            raise SyntaxError(\"Bad String dist type\")\n        data_list[i].append(choices[a])",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-7ac8abbf-f8e6-40b3-8778-6287d9ae4943",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "bcc9e420",
        "execution_millis": 3,
        "execution_start": 1619059521470,
        "deepnote_cell_type": "code"
      },
      "source": "list_of_names = [\"Kendrich Garner\", \"Xavion Douglas\", \"Dantrell Lucas\", \"Dashaud Dunn\", \"Stefon Vaughn\", \n\"Blake Mccoy\", \"Louvenia Murray\", \"Kwashay Houston\", \"Chineka Gray\", \"Kaeja Williams\", \"Tasia Floyd\", \"Chaybree Robertson\",\n\"Jori Henry\", \"Reginal Nash\", \"Calvon Gray\", \"Quandell Morris\", \"Tyrice Gordon\", \"Quintrell Whitfield\", \n\"Rhianna Miles\", \"Ashkira Bradford\", \"Dustina Graves\", \"Jomary Solomon\", \"Kamen Hawkins\", \"Odessa Morton\", \n\"Monifa Opeyemi\", \"Chukwuma Abiodun\", \"Boipelo Afolayan\", \"Tapiwa Botha\", \"Makena Kariuki\",\n\"Wambui Arendse\", \"Chidimma Ihejirika\", \"Akpan Okeke\", \"Oghenero Ayodele\", \"Oni Okeke\",\n\"Chidiegwu Babatunde\", \"Kwasi Mwangi\", \"Chiemeka Kariuki\", \"Chiumbo Adebayo\", \"Tsholofelo Afolayan\", \n\"Wanjiku Kariuki\", \"Sisay Idowu\", \"Ayaan Maina\", \"Efua Adebayo\", \"Issoufou Opeyemi\"]\n\ndef generate_name(names):\n    return np.random.choice(names)\n",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Working with Datetime",
      "metadata": {
        "tags": [],
        "cell_id": "00004-0de83742-e448-440d-a877-a45ca5e37088",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00010-f8e65d1f-8dea-4fb8-91ac-43e1a7133c89",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "939b5f5e",
        "execution_millis": 27,
        "execution_start": 1619059521981,
        "deepnote_cell_type": "code"
      },
      "source": "import datetime\nimport numpy as np\n\ndef generateDate(size, minYear, maxYear):\n    if type(size) != int or type(minYear) != int or type(maxYear) != int:\n        raise SyntaxError(\"size must be an integer\")\n    if len(str(minYear)) != 4 or len(str(maxYear)) != 4:\n        raise SyntaxError(\"year must be 4 digits\")\n    i=0\n    dates_lst = []\n    while i < size:\n        i+=1\n        dateVal = datetime.date(np.random.randint(minYear, maxYear), np.random.randint(1, 12), np.random.randint(1, 28))\n        dates_lst.append(str(dateVal))\n    \n    return dates_lst\n\ndateStuff = generateDate(50, 1900, 2000)\ndateStuff\n",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "['1905-10-19',\n '1943-06-24',\n '1980-07-21',\n '1935-03-09',\n '1974-07-15',\n '1976-02-26',\n '1955-07-19',\n '1917-09-20',\n '1901-11-24',\n '1986-04-26',\n '1973-03-10',\n '1958-09-23',\n '1993-06-22',\n '1953-04-14',\n '1901-02-21',\n '1957-03-23',\n '1954-06-09',\n '1997-03-20',\n '1996-11-23',\n '1966-05-01',\n '1997-04-07',\n '1973-06-01',\n '1991-01-19',\n '1923-03-22',\n '1990-10-12',\n '1931-05-23',\n '1943-09-03',\n '1912-02-05',\n '1965-09-01',\n '1964-03-13',\n '1933-09-21',\n '1911-06-07',\n '1944-11-22',\n '1915-03-02',\n '1936-02-06',\n '1907-11-05',\n '1922-03-01',\n '1950-02-26',\n '1999-07-10',\n '1950-05-27',\n '1937-05-09',\n '1997-08-04',\n '1979-07-13',\n '1920-08-21',\n '1943-04-02',\n '1935-05-25',\n '1967-02-10',\n '1952-09-15',\n '1970-10-06',\n '1987-10-21']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00004-22936b9b-d3d8-4e4e-acb5-fb0854c4f791",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "f8e6cbd8",
        "execution_millis": 10,
        "execution_start": 1619059522265,
        "deepnote_cell_type": "code"
      },
      "source": "import datetime\nfrom datetime import timedelta\n# ? \"BirthDate\"\n# : \n#   constraints: ~\n#   distribution: \n#     mean: \"5.5\"\n#     name: normal\n#     std: \"1.5\"\n#   strings: ./default/default_province.txt\n#   type: datetime\n\ndef generate_birthDate(size, minYear, maxYear):\n\n  def to_integer(dt_time):\n    return 1*dt_time.year\n\n  print(\"Birthdates and Deathdates\")\n  i = 0\n  birthdates_lst = []\n  deathdates_lst = []\n  while i < size: \n    i+=1\n    birthdate = datetime.date(np.random.randint(minYear, maxYear), np.random.randint(1, 12), np.random.randint(1, 28))\n    deathdate = datetime.date(np.random.randint(minYear+50, maxYear+50), np.random.randint(1, 12), np.random.randint(1, 28))\n    if to_integer(birthdate) > 1960:\n      birthdates_lst.append(str(birthdate))\n      deathdates_lst.append(\"N/A\")\n      # print(birthdates_lst)\n      # print(deathdates_lst)\n    else:\n      if to_integer(deathdate) < 2021:\n        birthdates_lst.append(str(birthdate))\n        deathdates_lst.append(str(deathdate))\n        # print(birthdates_lst)\n        # print(deathdates_lst)\n      else:\n        birthdates_lst.append(str(birthdate))\n        deathdates_lst.append(\"N/A\")\n        # print(birthdates_lst)\n        # print(deathdates_lst)\n\n  return birthdates_lst, deathdates_lst\n  \n    \n\n  \n\nbirthdateSample = generate_birthDate(50, 1900, 2000)\nbirthdateSample\n",
      "execution_count": 49,
      "outputs": [
        {
          "name": "stdout",
          "text": "Birthdates and Deathdates\n",
          "output_type": "stream"
        },
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "(['1900-08-20',\n  '1977-01-26',\n  '1905-01-18',\n  '1992-11-26',\n  '1922-10-15',\n  '1933-04-19',\n  '1977-04-13',\n  '1912-04-22',\n  '1923-06-09',\n  '1903-09-05',\n  '1962-09-11',\n  '1997-11-19',\n  '1908-08-07',\n  '1905-04-05',\n  '1985-06-04',\n  '1961-09-20',\n  '1976-03-21',\n  '1987-09-03',\n  '1965-04-06',\n  '1945-03-07',\n  '1930-01-13',\n  '1958-02-07',\n  '1930-06-19',\n  '1988-05-08',\n  '1992-01-15',\n  '1927-11-09',\n  '1937-06-02',\n  '1917-01-20',\n  '1903-11-21',\n  '1952-11-22',\n  '1995-06-03',\n  '1997-06-11',\n  '1954-02-25',\n  '1929-08-27',\n  '1939-05-13',\n  '1956-02-03',\n  '1957-02-02',\n  '1904-01-06',\n  '1989-11-15',\n  '1943-06-26',\n  '1946-02-08',\n  '1999-01-06',\n  '1960-06-27',\n  '1989-04-03',\n  '1934-10-14',\n  '1937-09-07',\n  '1980-03-12',\n  '1908-11-18',\n  '1996-09-14',\n  '1961-06-24'],\n ['N/A',\n  'N/A',\n  '1999-02-13',\n  'N/A',\n  'N/A',\n  '1976-08-10',\n  'N/A',\n  'N/A',\n  '2020-11-25',\n  '1969-10-20',\n  'N/A',\n  'N/A',\n  'N/A',\n  '2020-05-22',\n  'N/A',\n  'N/A',\n  'N/A',\n  'N/A',\n  'N/A',\n  '1960-09-22',\n  '1999-10-20',\n  '1970-10-22',\n  '1991-06-11',\n  'N/A',\n  'N/A',\n  '1984-02-07',\n  'N/A',\n  '1960-09-25',\n  '1984-08-08',\n  '1957-05-02',\n  'N/A',\n  'N/A',\n  '1993-10-07',\n  '2020-02-21',\n  'N/A',\n  '2011-05-09',\n  '2020-10-04',\n  'N/A',\n  'N/A',\n  'N/A',\n  'N/A',\n  'N/A',\n  '1998-04-25',\n  'N/A',\n  '2013-03-01',\n  'N/A',\n  'N/A',\n  'N/A',\n  'N/A',\n  'N/A'])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00006-418c2ffb-edb2-455d-8fdd-45e257bbc81e",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "dc1a23a3",
        "execution_millis": 23,
        "execution_start": 1619060904532,
        "deepnote_cell_type": "code"
      },
      "source": "import pandas as pd\ndef datagen(direc, filename):\n    assert type(direc) == str and type(filename) == str, \"datagen accepts a file directory and filename in string format as its arguments.\"\n    data_list = {}\n    try:\n        a = open(direc + filename)\n    except FileNotFoundError:\n        raise TypeError(\"File \" + direc + filename + \" does not exist at the specified directory.\")\n    except:\n        raise Exception(\"Another error occurred.\")\n    try:\n        loaded = yaml.load(a, Loader=yaml.FullLoader)\n    except:\n        raise SyntaxError(\"Improperly formatted yaml file: \" + direc + filename)\n    assert 'rows' in loaded, \"number of rows not specified in \" + direc + filename + \".\"\n    rows = loaded['rows']\n    assert type(rows) in [int, float] and rows >= 1, \"number of rows improperly specified in \" + direc + \".\"\n\n    for i in list(loaded)[1:]:\n        assert 'type' in loaded[i], \"no type for column \" + i\n        the_type = loaded[i]['type']\n        assert 'distribution' in loaded[i], \"no distribution specified for column \" + i\n        the_dist = loaded[i]['distribution']\n\n        the_consts = loaded[i]['constraints']\n\n        if the_type == 'int':\n            data_list[i] = int_generator(the_dist, the_consts, rows)\n        \n        elif the_type == 'float':\n            data_list[i] = float_generator(the_dist, the_consts, rows)\n        \n        elif the_type == 'string': \n            assert 'strings' in loaded[i] and type(loaded[i]['strings'] == str), 'improperly specified string path for ' + i\n            try:\n                choices = open(direc + loaded[i]['strings'],'r').read().split(\", \")\n            except:\n                raise FileNotFoundError(\"Bad file directory for \" + i + \":\" + direc + loaded[i]['strings'])\n            data_list[i] = []\n            string_bestower(the_dist, choices, i, data_list, rows)\n        \n        elif loaded[i]['type'] == 'date':\n            data_list[i] = generateDate(rows, the_consts['min'], the_consts['max'])\n            # OLD CODE BELOW\n            #if loaded[i]['pair_of_dates'] == 1:\n            #    generated = generate_birthDate(rows, the_consts['min'], the_consts['max'])\n            #    data_list[i + \"_start\"] = generated[0]\n            #    data_list[i + \"_end\"] = generated[1]\n            #elif loaded[i]['pair_of_dates'] == 0:\n            #    generated = generate_birthDate(rows, the_consts['min'], the_consts['max'])\n            #    data_list[i] = generated[0]\n        else:\n            raise SyntaxError(\"Type for \" + i + \" not 'int', 'float', 'string', or 'date': \" + loaded[i]['type'])\n        df = pd.DataFrame(data_list)\n    return df.to_csv(\"../synthetic-data/\" + filename[:-5] + \".csv\") #(CSV for each yaml file -> synthetic-data directory)\n\ndatagen(\"../yaml-files/\", \"properdelivery.yaml\")",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "File ../yaml-files/properly_delivery.yaml does not exist at the specified directory.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-4abead3fe8a4>\u001b[0m in \u001b[0;36mdatagen\u001b[0;34m(direc, filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirec\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../yaml-files/properly_delivery.yaml'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-4abead3fe8a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../synthetic-data/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(CSV for each yaml file -> synthetic-data directory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mdatagen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../yaml-files/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"properly_delivery.yaml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-100-4abead3fe8a4>\u001b[0m in \u001b[0;36mdatagen\u001b[0;34m(direc, filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirec\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdirec\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" does not exist at the specified directory.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Another error occurred.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: File ../yaml-files/properly_delivery.yaml does not exist at the specified directory."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "tags": [],
        "cell_id": "00012-0769b2c7-30ef-4935-a812-94e0ca314e67",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00007-7a7c2f90-6851-486b-918f-f5cba1cbb16b",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "bf2cce3b",
        "execution_millis": 8,
        "execution_start": 1619059523104,
        "deepnote_cell_type": "code"
      },
      "source": "def to_integer(dt_time):\n    return 1*dt_time.year\n\nbirthdate = datetime.date(np.random.randint(1920, 2000), np.random.randint(1, 12), np.random.randint(1, 28))\ndeathdate = datetime.date(np.random.randint(1920, 2000), np.random.randint(1, 12), np.random.randint(1, 28))\n    \nprint(to_integer(deathdate), to_integer(birthdate))",
      "execution_count": 51,
      "outputs": [
        {
          "name": "stdout",
          "text": "1942 1940\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00012-6104223c-e45d-4299-b0ac-31140a93468a",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ebb16ae8",
        "execution_millis": 49,
        "execution_start": 1619061091752,
        "deepnote_cell_type": "code"
      },
      "source": "from os import walk\ndef generate_all_yamls(yaml_directory):\n    returned = []\n\n    for root, dirs, files in walk(yaml_directory):\n        for filename in files:\n            if \".yaml\" in filename:\n                #try:\n                returned.append(datagen(yaml_directory, filename))\n                #except:\n                #    returned.append({filename: \"generation failed\"})\n    return returned\n\ngenerate_all_yamls(\"../yaml-files/\")\n#datagen(\"../yaml-files/\", \"properdelivery.yaml\")",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "Improperly formatted yaml file: ../yaml-files/deliveryTest.yaml (<string>)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"<ipython-input-102-e2329a444b8c>\"\u001b[0m, line \u001b[1;32m12\u001b[0m, in \u001b[1;35mdatagen\u001b[0m\n    loaded = yaml.load(a, Loader=yaml.FullLoader)\n",
            "  File \u001b[1;32m\"/shared-libs/python3.7/py/lib/python3.7/site-packages/yaml/__init__.py\"\u001b[0m, line \u001b[1;32m114\u001b[0m, in \u001b[1;35mload\u001b[0m\n    return loader.get_single_data()\n",
            "  File \u001b[1;32m\"/shared-libs/python3.7/py/lib/python3.7/site-packages/yaml/constructor.py\"\u001b[0m, line \u001b[1;32m49\u001b[0m, in \u001b[1;35mget_single_data\u001b[0m\n    node = self.get_single_node()\n",
            "  File \u001b[1;32m\"/shared-libs/python3.7/py/lib/python3.7/site-packages/yaml/composer.py\"\u001b[0m, line \u001b[1;32m36\u001b[0m, in \u001b[1;35mget_single_node\u001b[0m\n    document = self.compose_document()\n",
            "  File \u001b[1;32m\"/shared-libs/python3.7/py/lib/python3.7/site-packages/yaml/composer.py\"\u001b[0m, line \u001b[1;32m55\u001b[0m, in \u001b[1;35mcompose_document\u001b[0m\n    node = self.compose_node(None, None)\n",
            "  File \u001b[1;32m\"/shared-libs/python3.7/py/lib/python3.7/site-packages/yaml/composer.py\"\u001b[0m, line \u001b[1;32m84\u001b[0m, in \u001b[1;35mcompose_node\u001b[0m\n    node = self.compose_mapping_node(anchor)\n",
            "  File \u001b[1;32m\"/shared-libs/python3.7/py/lib/python3.7/site-packages/yaml/composer.py\"\u001b[0m, line \u001b[1;32m127\u001b[0m, in \u001b[1;35mcompose_mapping_node\u001b[0m\n    while not self.check_event(MappingEndEvent):\n",
            "  File \u001b[1;32m\"/shared-libs/python3.7/py/lib/python3.7/site-packages/yaml/parser.py\"\u001b[0m, line \u001b[1;32m98\u001b[0m, in \u001b[1;35mcheck_event\u001b[0m\n    self.current_event = self.state()\n",
            "\u001b[0;36m  File \u001b[0;32m\"/shared-libs/python3.7/py/lib/python3.7/site-packages/yaml/parser.py\"\u001b[0;36m, line \u001b[0;32m439\u001b[0;36m, in \u001b[0;35mparse_block_mapping_key\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"expected <block end>, but found %r\" % token.id, token.start_mark)\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m\u001b[0;31m:\u001b[0m while parsing a block mapping\n  in \"../yaml-files/deliveryTest.yaml\", line 2, column 1\nexpected <block end>, but found '-'\n  in \"../yaml-files/deliveryTest.yaml\", line 115, column 1\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3437\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-108-7b7bb9b61a3e>\"\u001b[0m, line \u001b[1;32m14\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    generate_all_yamls(\"../yaml-files/\")\n",
            "  File \u001b[1;32m\"<ipython-input-108-7b7bb9b61a3e>\"\u001b[0m, line \u001b[1;32m9\u001b[0m, in \u001b[1;35mgenerate_all_yamls\u001b[0m\n    returned.append(datagen(yaml_directory, filename))\n",
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-102-e2329a444b8c>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0;36m, in \u001b[0;35mdatagen\u001b[0;36m\u001b[0m\n\u001b[0;31m    raise SyntaxError(\"Improperly formatted yaml file: \" + direc + filename)\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Improperly formatted yaml file: ../yaml-files/deliveryTest.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00013-286b9926-77af-4eba-b965-2d80dea129eb",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a760a4c6",
        "execution_millis": 19,
        "execution_start": 1619060302123,
        "deepnote_cell_type": "code"
      },
      "source": "",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../yaml-files/default/default_province.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-a8ae05c6c8fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../yaml-files/default/default_province.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../yaml-files/default/default_province.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "tags": [],
        "cell_id": "00015-67e8f86f-c1d9-4d67-8d6c-c994fca77304",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=59003b3a-4258-4703-b30d-75642543bba1' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_notebook_id": "56fe02cc-48aa-46db-9e7a-354e7bdc62cd",
    "deepnote_execution_queue": []
  }
}